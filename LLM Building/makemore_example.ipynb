{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "words = open('names.txt', 'r').read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[:10]\n",
    "min(len(w) for w in words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e m\n",
      "m m\n",
      "m a\n",
      "o l\n",
      "l i\n",
      "i v\n",
      "v i\n",
      "i a\n",
      "a v\n",
      "v a\n"
     ]
    }
   ],
   "source": [
    "for w in words[:3]:\n",
    "    chs = ['<S>'] + list(w) + ['<E>'] # introduce special start and end characters\n",
    "    for ch1, ch2 in zip(w, w[1:]):\n",
    "        print(ch1,ch2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('n', '.'), 6763),\n",
       " (('a', '.'), 6640),\n",
       " (('a', 'n'), 5438),\n",
       " (('.', 'a'), 4410),\n",
       " (('e', '.'), 3983),\n",
       " (('a', 'r'), 3264),\n",
       " (('e', 'l'), 3248),\n",
       " (('r', 'i'), 3033),\n",
       " (('n', 'a'), 2977),\n",
       " (('.', 'k'), 2963),\n",
       " (('l', 'e'), 2921),\n",
       " (('e', 'n'), 2675),\n",
       " (('l', 'a'), 2623),\n",
       " (('m', 'a'), 2590),\n",
       " (('.', 'm'), 2538),\n",
       " (('a', 'l'), 2528),\n",
       " (('i', '.'), 2489),\n",
       " (('l', 'i'), 2480),\n",
       " (('i', 'a'), 2445),\n",
       " (('.', 'j'), 2422),\n",
       " (('o', 'n'), 2411),\n",
       " (('h', '.'), 2409),\n",
       " (('r', 'a'), 2356),\n",
       " (('a', 'h'), 2332),\n",
       " (('h', 'a'), 2244),\n",
       " (('y', 'a'), 2143),\n",
       " (('i', 'n'), 2126),\n",
       " (('.', 's'), 2055),\n",
       " (('a', 'y'), 2050),\n",
       " (('y', '.'), 2007),\n",
       " (('e', 'r'), 1958),\n",
       " (('n', 'n'), 1906),\n",
       " (('y', 'n'), 1826),\n",
       " (('k', 'a'), 1731),\n",
       " (('n', 'i'), 1725),\n",
       " (('r', 'e'), 1697),\n",
       " (('.', 'd'), 1690),\n",
       " (('i', 'e'), 1653),\n",
       " (('a', 'i'), 1650),\n",
       " (('.', 'r'), 1639),\n",
       " (('a', 'm'), 1634),\n",
       " (('l', 'y'), 1588),\n",
       " (('.', 'l'), 1572),\n",
       " (('.', 'c'), 1542),\n",
       " (('.', 'e'), 1531),\n",
       " (('j', 'a'), 1473),\n",
       " (('r', '.'), 1377),\n",
       " (('n', 'e'), 1359),\n",
       " (('l', 'l'), 1345),\n",
       " (('i', 'l'), 1345),\n",
       " (('i', 's'), 1316),\n",
       " (('l', '.'), 1314),\n",
       " (('.', 't'), 1308),\n",
       " (('.', 'b'), 1306),\n",
       " (('d', 'a'), 1303),\n",
       " (('s', 'h'), 1285),\n",
       " (('d', 'e'), 1283),\n",
       " (('e', 'e'), 1271),\n",
       " (('m', 'i'), 1256),\n",
       " (('s', 'a'), 1201),\n",
       " (('s', '.'), 1169),\n",
       " (('.', 'n'), 1146),\n",
       " (('a', 's'), 1118),\n",
       " (('y', 'l'), 1104),\n",
       " (('e', 'y'), 1070),\n",
       " (('o', 'r'), 1059),\n",
       " (('a', 'd'), 1042),\n",
       " (('t', 'a'), 1027),\n",
       " (('.', 'z'), 929),\n",
       " (('v', 'i'), 911),\n",
       " (('k', 'e'), 895),\n",
       " (('s', 'e'), 884),\n",
       " (('.', 'h'), 874),\n",
       " (('r', 'o'), 869),\n",
       " (('e', 's'), 861),\n",
       " (('z', 'a'), 860),\n",
       " (('o', '.'), 855),\n",
       " (('i', 'r'), 849),\n",
       " (('b', 'r'), 842),\n",
       " (('a', 'v'), 834),\n",
       " (('m', 'e'), 818),\n",
       " (('e', 'i'), 818),\n",
       " (('c', 'a'), 815),\n",
       " (('i', 'y'), 779),\n",
       " (('r', 'y'), 773),\n",
       " (('e', 'm'), 769),\n",
       " (('s', 't'), 765),\n",
       " (('h', 'i'), 729),\n",
       " (('t', 'e'), 716),\n",
       " (('n', 'd'), 704),\n",
       " (('l', 'o'), 692),\n",
       " (('a', 'e'), 692),\n",
       " (('a', 't'), 687),\n",
       " (('s', 'i'), 684),\n",
       " (('e', 'a'), 679),\n",
       " (('d', 'i'), 674),\n",
       " (('h', 'e'), 674),\n",
       " (('.', 'g'), 669),\n",
       " (('t', 'o'), 667),\n",
       " (('c', 'h'), 664),\n",
       " (('b', 'e'), 655),\n",
       " (('t', 'h'), 647),\n",
       " (('v', 'a'), 642),\n",
       " (('o', 'l'), 619),\n",
       " (('.', 'i'), 591),\n",
       " (('i', 'o'), 588),\n",
       " (('e', 't'), 580),\n",
       " (('v', 'e'), 568),\n",
       " (('a', 'k'), 568),\n",
       " (('a', 'a'), 556),\n",
       " (('c', 'e'), 551),\n",
       " (('a', 'b'), 541),\n",
       " (('i', 't'), 541),\n",
       " (('.', 'y'), 535),\n",
       " (('t', 'i'), 532),\n",
       " (('s', 'o'), 531),\n",
       " (('m', '.'), 516),\n",
       " (('d', '.'), 516),\n",
       " (('.', 'p'), 515),\n",
       " (('i', 'c'), 509),\n",
       " (('k', 'i'), 509),\n",
       " (('o', 's'), 504),\n",
       " (('n', 'o'), 496),\n",
       " (('t', '.'), 483),\n",
       " (('j', 'o'), 479),\n",
       " (('u', 's'), 474),\n",
       " (('a', 'c'), 470),\n",
       " (('n', 'y'), 465),\n",
       " (('e', 'v'), 463),\n",
       " (('s', 's'), 461),\n",
       " (('m', 'o'), 452),\n",
       " (('i', 'k'), 445),\n",
       " (('n', 't'), 443),\n",
       " (('i', 'd'), 440),\n",
       " (('j', 'e'), 440),\n",
       " (('a', 'z'), 435),\n",
       " (('i', 'g'), 428),\n",
       " (('i', 'm'), 427),\n",
       " (('r', 'r'), 425),\n",
       " (('d', 'r'), 424),\n",
       " (('.', 'f'), 417),\n",
       " (('u', 'r'), 414),\n",
       " (('r', 'l'), 413),\n",
       " (('y', 's'), 401),\n",
       " (('.', 'o'), 394),\n",
       " (('e', 'd'), 384),\n",
       " (('a', 'u'), 381),\n",
       " (('c', 'o'), 380),\n",
       " (('k', 'y'), 379),\n",
       " (('d', 'o'), 378),\n",
       " (('.', 'v'), 376),\n",
       " (('t', 't'), 374),\n",
       " (('z', 'e'), 373),\n",
       " (('z', 'i'), 364),\n",
       " (('k', '.'), 363),\n",
       " (('g', 'h'), 360),\n",
       " (('t', 'r'), 352),\n",
       " (('k', 'o'), 344),\n",
       " (('t', 'y'), 341),\n",
       " (('g', 'e'), 334),\n",
       " (('g', 'a'), 330),\n",
       " (('l', 'u'), 324),\n",
       " (('b', 'a'), 321),\n",
       " (('d', 'y'), 317),\n",
       " (('c', 'k'), 316),\n",
       " (('.', 'w'), 307),\n",
       " (('k', 'h'), 307),\n",
       " (('u', 'l'), 301),\n",
       " (('y', 'e'), 301),\n",
       " (('y', 'r'), 291),\n",
       " (('m', 'y'), 287),\n",
       " (('h', 'o'), 287),\n",
       " (('w', 'a'), 280),\n",
       " (('s', 'l'), 279),\n",
       " (('n', 's'), 278),\n",
       " (('i', 'z'), 277),\n",
       " (('u', 'n'), 275),\n",
       " (('o', 'u'), 275),\n",
       " (('n', 'g'), 273),\n",
       " (('y', 'd'), 272),\n",
       " (('c', 'i'), 271),\n",
       " (('y', 'o'), 271),\n",
       " (('i', 'v'), 269),\n",
       " (('e', 'o'), 269),\n",
       " (('o', 'm'), 261),\n",
       " (('r', 'u'), 252),\n",
       " (('f', 'a'), 242),\n",
       " (('b', 'i'), 217),\n",
       " (('s', 'y'), 215),\n",
       " (('n', 'c'), 213),\n",
       " (('h', 'y'), 213),\n",
       " (('p', 'a'), 209),\n",
       " (('r', 't'), 208),\n",
       " (('q', 'u'), 206),\n",
       " (('p', 'h'), 204),\n",
       " (('h', 'r'), 204),\n",
       " (('j', 'u'), 202),\n",
       " (('g', 'r'), 201),\n",
       " (('p', 'e'), 197),\n",
       " (('n', 'l'), 195),\n",
       " (('y', 'i'), 192),\n",
       " (('g', 'i'), 190),\n",
       " (('o', 'd'), 190),\n",
       " (('r', 's'), 190),\n",
       " (('r', 'd'), 187),\n",
       " (('h', 'l'), 185),\n",
       " (('s', 'u'), 185),\n",
       " (('a', 'x'), 182),\n",
       " (('e', 'z'), 181),\n",
       " (('e', 'k'), 178),\n",
       " (('o', 'v'), 176),\n",
       " (('a', 'j'), 175),\n",
       " (('o', 'h'), 171),\n",
       " (('u', 'e'), 169),\n",
       " (('m', 'm'), 168),\n",
       " (('a', 'g'), 168),\n",
       " (('h', 'u'), 166),\n",
       " (('x', '.'), 164),\n",
       " (('u', 'a'), 163),\n",
       " (('r', 'm'), 162),\n",
       " (('a', 'w'), 161),\n",
       " (('f', 'i'), 160),\n",
       " (('z', '.'), 160),\n",
       " (('u', '.'), 155),\n",
       " (('u', 'm'), 154),\n",
       " (('e', 'c'), 153),\n",
       " (('v', 'o'), 153),\n",
       " (('e', 'h'), 152),\n",
       " (('p', 'r'), 151),\n",
       " (('d', 'd'), 149),\n",
       " (('o', 'a'), 149),\n",
       " (('w', 'e'), 149),\n",
       " (('w', 'i'), 148),\n",
       " (('y', 'm'), 148),\n",
       " (('z', 'y'), 147),\n",
       " (('n', 'z'), 145),\n",
       " (('y', 'u'), 141),\n",
       " (('r', 'n'), 140),\n",
       " (('o', 'b'), 140),\n",
       " (('k', 'l'), 139),\n",
       " (('m', 'u'), 139),\n",
       " (('l', 'd'), 138),\n",
       " (('h', 'n'), 138),\n",
       " (('u', 'd'), 136),\n",
       " (('.', 'x'), 134),\n",
       " (('t', 'l'), 134),\n",
       " (('a', 'f'), 134),\n",
       " (('o', 'e'), 132),\n",
       " (('e', 'x'), 132),\n",
       " (('e', 'g'), 125),\n",
       " (('f', 'e'), 123),\n",
       " (('z', 'l'), 123),\n",
       " (('u', 'i'), 121),\n",
       " (('v', 'y'), 121),\n",
       " (('e', 'b'), 121),\n",
       " (('r', 'h'), 121),\n",
       " (('j', 'i'), 119),\n",
       " (('o', 't'), 118),\n",
       " (('d', 'h'), 118),\n",
       " (('h', 'm'), 117),\n",
       " (('c', 'l'), 116),\n",
       " (('o', 'o'), 115),\n",
       " (('y', 'c'), 115),\n",
       " (('o', 'w'), 114),\n",
       " (('o', 'c'), 114),\n",
       " (('f', 'r'), 114),\n",
       " (('b', '.'), 114),\n",
       " (('m', 'b'), 112),\n",
       " (('z', 'o'), 110),\n",
       " (('i', 'b'), 110),\n",
       " (('i', 'u'), 109),\n",
       " (('k', 'r'), 109),\n",
       " (('g', '.'), 108),\n",
       " (('y', 'v'), 106),\n",
       " (('t', 'z'), 105),\n",
       " (('b', 'o'), 105),\n",
       " (('c', 'y'), 104),\n",
       " (('y', 't'), 104),\n",
       " (('u', 'b'), 103),\n",
       " (('u', 'c'), 103),\n",
       " (('x', 'a'), 103),\n",
       " (('b', 'l'), 103),\n",
       " (('o', 'y'), 103),\n",
       " (('x', 'i'), 102),\n",
       " (('i', 'f'), 101),\n",
       " (('r', 'c'), 99),\n",
       " (('c', '.'), 97),\n",
       " (('m', 'r'), 97),\n",
       " (('n', 'u'), 96),\n",
       " (('o', 'p'), 95),\n",
       " (('i', 'h'), 95),\n",
       " (('k', 's'), 95),\n",
       " (('l', 's'), 94),\n",
       " (('u', 'k'), 93),\n",
       " (('.', 'q'), 92),\n",
       " (('d', 'u'), 92),\n",
       " (('s', 'm'), 90),\n",
       " (('r', 'k'), 90),\n",
       " (('i', 'x'), 89),\n",
       " (('v', '.'), 88),\n",
       " (('y', 'k'), 86),\n",
       " (('u', 'w'), 86),\n",
       " (('g', 'u'), 85),\n",
       " (('b', 'y'), 83),\n",
       " (('e', 'p'), 83),\n",
       " (('g', 'o'), 83),\n",
       " (('s', 'k'), 82),\n",
       " (('u', 't'), 82),\n",
       " (('a', 'p'), 82),\n",
       " (('e', 'f'), 82),\n",
       " (('i', 'i'), 82),\n",
       " (('r', 'v'), 80),\n",
       " (('f', '.'), 80),\n",
       " (('t', 'u'), 78),\n",
       " (('y', 'z'), 78),\n",
       " (('.', 'u'), 78),\n",
       " (('l', 't'), 77),\n",
       " (('r', 'g'), 76),\n",
       " (('c', 'r'), 76),\n",
       " (('i', 'j'), 76),\n",
       " (('w', 'y'), 73),\n",
       " (('z', 'u'), 73),\n",
       " (('l', 'v'), 72),\n",
       " (('h', 't'), 71),\n",
       " (('j', '.'), 71),\n",
       " (('x', 't'), 70),\n",
       " (('o', 'i'), 69),\n",
       " (('e', 'u'), 69),\n",
       " (('o', 'k'), 68),\n",
       " (('b', 'd'), 65),\n",
       " (('a', 'o'), 63),\n",
       " (('p', 'i'), 61),\n",
       " (('s', 'c'), 60),\n",
       " (('d', 'l'), 60),\n",
       " (('l', 'm'), 60),\n",
       " (('a', 'q'), 60),\n",
       " (('f', 'o'), 60),\n",
       " (('p', 'o'), 59),\n",
       " (('n', 'k'), 58),\n",
       " (('w', 'n'), 58),\n",
       " (('u', 'h'), 58),\n",
       " (('e', 'j'), 55),\n",
       " (('n', 'v'), 55),\n",
       " (('s', 'r'), 55),\n",
       " (('o', 'z'), 54),\n",
       " (('i', 'p'), 53),\n",
       " (('l', 'b'), 52),\n",
       " (('i', 'q'), 52),\n",
       " (('w', '.'), 51),\n",
       " (('m', 'c'), 51),\n",
       " (('s', 'p'), 51),\n",
       " (('e', 'w'), 50),\n",
       " (('k', 'u'), 50),\n",
       " (('v', 'r'), 48),\n",
       " (('u', 'g'), 47),\n",
       " (('o', 'x'), 45),\n",
       " (('u', 'z'), 45),\n",
       " (('z', 'z'), 45),\n",
       " (('j', 'h'), 45),\n",
       " (('b', 'u'), 45),\n",
       " (('o', 'g'), 44),\n",
       " (('n', 'r'), 44),\n",
       " (('f', 'f'), 44),\n",
       " (('n', 'j'), 44),\n",
       " (('z', 'h'), 43),\n",
       " (('c', 'c'), 42),\n",
       " (('r', 'b'), 41),\n",
       " (('x', 'o'), 41),\n",
       " (('b', 'h'), 41),\n",
       " (('p', 'p'), 39),\n",
       " (('x', 'l'), 39),\n",
       " (('h', 'v'), 39),\n",
       " (('b', 'b'), 38),\n",
       " (('m', 'p'), 38),\n",
       " (('x', 'x'), 38),\n",
       " (('u', 'v'), 37),\n",
       " (('x', 'e'), 36),\n",
       " (('w', 'o'), 36),\n",
       " (('c', 't'), 35),\n",
       " (('z', 'm'), 35),\n",
       " (('t', 's'), 35),\n",
       " (('m', 's'), 35),\n",
       " (('c', 'u'), 35),\n",
       " (('o', 'f'), 34),\n",
       " (('u', 'x'), 34),\n",
       " (('k', 'w'), 34),\n",
       " (('p', '.'), 33),\n",
       " (('g', 'l'), 32),\n",
       " (('z', 'r'), 32),\n",
       " (('d', 'n'), 31),\n",
       " (('g', 't'), 31),\n",
       " (('g', 'y'), 31),\n",
       " (('h', 's'), 31),\n",
       " (('x', 's'), 31),\n",
       " (('g', 's'), 30),\n",
       " (('x', 'y'), 30),\n",
       " (('y', 'g'), 30),\n",
       " (('d', 'm'), 30),\n",
       " (('d', 's'), 29),\n",
       " (('h', 'k'), 29),\n",
       " (('y', 'x'), 28),\n",
       " (('q', '.'), 28),\n",
       " (('g', 'n'), 27),\n",
       " (('y', 'b'), 27),\n",
       " (('g', 'w'), 26),\n",
       " (('n', 'h'), 26),\n",
       " (('k', 'n'), 26),\n",
       " (('g', 'g'), 25),\n",
       " (('d', 'g'), 25),\n",
       " (('l', 'c'), 25),\n",
       " (('r', 'j'), 25),\n",
       " (('w', 'u'), 25),\n",
       " (('l', 'k'), 24),\n",
       " (('m', 'd'), 24),\n",
       " (('s', 'w'), 24),\n",
       " (('s', 'n'), 24),\n",
       " (('h', 'd'), 24),\n",
       " (('w', 'h'), 23),\n",
       " (('y', 'j'), 23),\n",
       " (('y', 'y'), 23),\n",
       " (('r', 'z'), 23),\n",
       " (('d', 'w'), 23),\n",
       " (('w', 'r'), 22),\n",
       " (('t', 'n'), 22),\n",
       " (('l', 'f'), 22),\n",
       " (('y', 'h'), 22),\n",
       " (('r', 'w'), 21),\n",
       " (('s', 'b'), 21),\n",
       " (('m', 'n'), 20),\n",
       " (('f', 'l'), 20),\n",
       " (('w', 's'), 20),\n",
       " (('k', 'k'), 20),\n",
       " (('h', 'z'), 20),\n",
       " (('g', 'd'), 19),\n",
       " (('l', 'h'), 19),\n",
       " (('n', 'm'), 19),\n",
       " (('x', 'z'), 19),\n",
       " (('u', 'f'), 19),\n",
       " (('f', 't'), 18),\n",
       " (('l', 'r'), 18),\n",
       " (('p', 't'), 17),\n",
       " (('t', 'c'), 17),\n",
       " (('k', 't'), 17),\n",
       " (('d', 'v'), 17),\n",
       " (('u', 'p'), 16),\n",
       " (('p', 'l'), 16),\n",
       " (('l', 'w'), 16),\n",
       " (('p', 's'), 16),\n",
       " (('o', 'j'), 16),\n",
       " (('r', 'q'), 16),\n",
       " (('y', 'p'), 15),\n",
       " (('l', 'p'), 15),\n",
       " (('t', 'v'), 15),\n",
       " (('r', 'p'), 14),\n",
       " (('l', 'n'), 14),\n",
       " (('e', 'q'), 14),\n",
       " (('f', 'y'), 14),\n",
       " (('s', 'v'), 14),\n",
       " (('u', 'j'), 14),\n",
       " (('v', 'l'), 14),\n",
       " (('q', 'a'), 13),\n",
       " (('u', 'y'), 13),\n",
       " (('q', 'i'), 13),\n",
       " (('w', 'l'), 13),\n",
       " (('p', 'y'), 12),\n",
       " (('y', 'f'), 12),\n",
       " (('c', 'q'), 11),\n",
       " (('j', 'r'), 11),\n",
       " (('n', 'w'), 11),\n",
       " (('n', 'f'), 11),\n",
       " (('t', 'w'), 11),\n",
       " (('m', 'z'), 11),\n",
       " (('u', 'o'), 10),\n",
       " (('f', 'u'), 10),\n",
       " (('l', 'z'), 10),\n",
       " (('h', 'w'), 10),\n",
       " (('u', 'q'), 10),\n",
       " (('j', 'y'), 10),\n",
       " (('s', 'z'), 10),\n",
       " (('s', 'd'), 9),\n",
       " (('j', 'l'), 9),\n",
       " (('d', 'j'), 9),\n",
       " (('k', 'm'), 9),\n",
       " (('r', 'f'), 9),\n",
       " (('h', 'j'), 9),\n",
       " (('v', 'n'), 8),\n",
       " (('n', 'b'), 8),\n",
       " (('i', 'w'), 8),\n",
       " (('h', 'b'), 8),\n",
       " (('b', 's'), 8),\n",
       " (('w', 't'), 8),\n",
       " (('w', 'd'), 8),\n",
       " (('v', 'v'), 7),\n",
       " (('v', 'u'), 7),\n",
       " (('j', 's'), 7),\n",
       " (('m', 'j'), 7),\n",
       " (('f', 's'), 6),\n",
       " (('l', 'g'), 6),\n",
       " (('l', 'j'), 6),\n",
       " (('j', 'w'), 6),\n",
       " (('n', 'x'), 6),\n",
       " (('y', 'q'), 6),\n",
       " (('w', 'k'), 6),\n",
       " (('g', 'm'), 6),\n",
       " (('x', 'u'), 5),\n",
       " (('m', 'h'), 5),\n",
       " (('m', 'l'), 5),\n",
       " (('j', 'm'), 5),\n",
       " (('c', 's'), 5),\n",
       " (('j', 'v'), 5),\n",
       " (('n', 'p'), 5),\n",
       " (('d', 'f'), 5),\n",
       " (('x', 'd'), 5),\n",
       " (('z', 'b'), 4),\n",
       " (('f', 'n'), 4),\n",
       " (('x', 'c'), 4),\n",
       " (('m', 't'), 4),\n",
       " (('t', 'm'), 4),\n",
       " (('z', 'n'), 4),\n",
       " (('z', 't'), 4),\n",
       " (('p', 'u'), 4),\n",
       " (('c', 'z'), 4),\n",
       " (('b', 'n'), 4),\n",
       " (('z', 's'), 4),\n",
       " (('f', 'w'), 4),\n",
       " (('d', 't'), 4),\n",
       " (('j', 'd'), 4),\n",
       " (('j', 'c'), 4),\n",
       " (('y', 'w'), 4),\n",
       " (('v', 'k'), 3),\n",
       " (('x', 'w'), 3),\n",
       " (('t', 'j'), 3),\n",
       " (('c', 'j'), 3),\n",
       " (('q', 'w'), 3),\n",
       " (('g', 'b'), 3),\n",
       " (('o', 'q'), 3),\n",
       " (('r', 'x'), 3),\n",
       " (('d', 'c'), 3),\n",
       " (('g', 'j'), 3),\n",
       " (('x', 'f'), 3),\n",
       " (('z', 'w'), 3),\n",
       " (('d', 'k'), 3),\n",
       " (('u', 'u'), 3),\n",
       " (('m', 'v'), 3),\n",
       " (('c', 'x'), 3),\n",
       " (('l', 'q'), 3),\n",
       " (('p', 'b'), 2),\n",
       " (('t', 'g'), 2),\n",
       " (('q', 's'), 2),\n",
       " (('t', 'x'), 2),\n",
       " (('f', 'k'), 2),\n",
       " (('b', 't'), 2),\n",
       " (('j', 'n'), 2),\n",
       " (('k', 'c'), 2),\n",
       " (('z', 'k'), 2),\n",
       " (('s', 'j'), 2),\n",
       " (('s', 'f'), 2),\n",
       " (('z', 'j'), 2),\n",
       " (('n', 'q'), 2),\n",
       " (('f', 'z'), 2),\n",
       " (('h', 'g'), 2),\n",
       " (('w', 'w'), 2),\n",
       " (('k', 'j'), 2),\n",
       " (('j', 'k'), 2),\n",
       " (('w', 'm'), 2),\n",
       " (('z', 'c'), 2),\n",
       " (('z', 'v'), 2),\n",
       " (('w', 'f'), 2),\n",
       " (('q', 'm'), 2),\n",
       " (('k', 'z'), 2),\n",
       " (('j', 'j'), 2),\n",
       " (('z', 'p'), 2),\n",
       " (('j', 't'), 2),\n",
       " (('k', 'b'), 2),\n",
       " (('m', 'w'), 2),\n",
       " (('h', 'f'), 2),\n",
       " (('c', 'g'), 2),\n",
       " (('t', 'f'), 2),\n",
       " (('h', 'c'), 2),\n",
       " (('q', 'o'), 2),\n",
       " (('k', 'd'), 2),\n",
       " (('k', 'v'), 2),\n",
       " (('s', 'g'), 2),\n",
       " (('z', 'd'), 2),\n",
       " (('q', 'r'), 1),\n",
       " (('d', 'z'), 1),\n",
       " (('p', 'j'), 1),\n",
       " (('q', 'l'), 1),\n",
       " (('p', 'f'), 1),\n",
       " (('q', 'e'), 1),\n",
       " (('b', 'c'), 1),\n",
       " (('c', 'd'), 1),\n",
       " (('m', 'f'), 1),\n",
       " (('p', 'n'), 1),\n",
       " (('w', 'b'), 1),\n",
       " (('p', 'c'), 1),\n",
       " (('h', 'p'), 1),\n",
       " (('f', 'h'), 1),\n",
       " (('b', 'j'), 1),\n",
       " (('f', 'g'), 1),\n",
       " (('z', 'g'), 1),\n",
       " (('c', 'p'), 1),\n",
       " (('p', 'k'), 1),\n",
       " (('p', 'm'), 1),\n",
       " (('x', 'n'), 1),\n",
       " (('s', 'q'), 1),\n",
       " (('k', 'f'), 1),\n",
       " (('m', 'k'), 1),\n",
       " (('x', 'h'), 1),\n",
       " (('g', 'f'), 1),\n",
       " (('v', 'b'), 1),\n",
       " (('j', 'p'), 1),\n",
       " (('g', 'z'), 1),\n",
       " (('v', 'd'), 1),\n",
       " (('d', 'b'), 1),\n",
       " (('v', 'h'), 1),\n",
       " (('h', 'h'), 1),\n",
       " (('g', 'v'), 1),\n",
       " (('d', 'q'), 1),\n",
       " (('x', 'b'), 1),\n",
       " (('w', 'z'), 1),\n",
       " (('h', 'q'), 1),\n",
       " (('j', 'b'), 1),\n",
       " (('x', 'm'), 1),\n",
       " (('w', 'g'), 1),\n",
       " (('t', 'b'), 1),\n",
       " (('z', 'x'), 1)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bigram model of above\n",
    "\n",
    "b = {} #dictionary\n",
    "for w in words:\n",
    "    # chs = ['<S>'] + list(w) + ['<E>']\n",
    "    chs = ['.'] + list(w) + ['.']\n",
    "    for ch1, ch2 in zip(chs, chs[1:]):\n",
    "       bigram = (ch1, ch2)\n",
    "       b[bigram] = b.get(bigram, 0) + 1\n",
    "sorted(b.items(), key = lambda kv: -kv[1]) # sorts the dictionary by key value at space 1 (default is 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = torch.zeros((28,28), dtype=torch.int32) # 28x28 array of zeros \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joining all words into one long list, removing duplicates, \n",
    "# sorting them, and then converting them into a list of characters\n",
    "\n",
    "chars = sorted(list(set(''.join(words)))) # set of all characters in the words\n",
    "char2int = {ch:i+1 for i,ch in enumerate(chars)} # dictionary of characters to integers\n",
    "# char2int['<S>'] = 26\n",
    "# char2int['<E>'] = 27 # start and end characters\n",
    "char2int['.'] = 0\n",
    "char2int\n",
    "int2char = {i:ch for ch,i in char2int.items()} # dictionary of integers to characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling the tensor with the counts of bigrams\n",
    "for w in words:\n",
    "    chs = ['.'] + list(w) + ['.']\n",
    "    for ch1, ch2 in zip(chs, chs[1:]):\n",
    "        ix1 = char2int[ch1]\n",
    "        ix2 = char2int[ch2]\n",
    "        N[ix1, ix2] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   0, 4410, 1306, 1542, 1690, 1531,  417,  669,  874,  591, 2422, 2963,\n",
       "        1572, 2538, 1146,  394,  515,   92, 1639, 2055, 1308,   78,  376,  307,\n",
       "         134,  535,  929,    0], dtype=torch.int32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.1377, 0.0408, 0.0481, 0.0528, 0.0478, 0.0130, 0.0209, 0.0273,\n",
       "        0.0184, 0.0756, 0.0925, 0.0491, 0.0792, 0.0358, 0.0123, 0.0161, 0.0029,\n",
       "        0.0512, 0.0642, 0.0408, 0.0024, 0.0117, 0.0096, 0.0042, 0.0167, 0.0290,\n",
       "        0.0000])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting first row to probabilities\n",
    "p = N[0].float()\n",
    "p = p / p.sum( )\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "j u n i d e .\n",
      "j a n a s a h .\n",
      "p .\n",
      "c o n y .\n",
      "a .\n",
      "n n .\n",
      "k o h i n .\n",
      "t o l i a n .\n",
      "j u e e .\n",
      "k s a h n a a u r a n i l e v i a s .\n",
      "d e d a i n r w i e t a .\n",
      "s s o n i e l y l a r t e .\n",
      "f a v e u m e r i f o n t u m e .\n",
      "p h y n s l e n a r u a n i .\n",
      "c o r e .\n",
      "y a e n o n .\n",
      "k a .\n",
      "j a b d i n e r i m i k i m a y n i n .\n",
      "a n a a s n .\n",
      "s s o r i o n s u s h .\n",
      "d g o s s m i t a n .\n",
      "i l .\n",
      "l e .\n",
      "p a n n .\n",
      "t h a t .\n",
      "j a n r e l i .\n",
      "i s a .\n",
      "d y n .\n",
      "r i j e l u m e m a h a u n a y a l e v a .\n",
      "c a r a r r .\n",
      "j e n .\n",
      "j a n a r t a .\n",
      "m a l y .\n",
      "a b e l y .\n",
      "a .\n",
      "i .\n",
      "l a v a d o n i .\n",
      "t h e m i e l y a w a t .\n",
      "f .\n",
      "m o d a m .\n",
      "t a v i l i t i k i e s a l o e v e r i n .\n",
      "n .\n",
      "e .\n",
      "k a l b r e n e l a h .\n",
      "a n e n .\n",
      "c h .\n",
      "k .\n",
      "j a n .\n",
      "o d r i d r d e n a n i a l i l p e r g h a .\n",
      "t e z r a l e l i a .\n"
     ]
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "\n",
    "# generating names based on bigram model using probability distribution\n",
    "for i in range(50):\n",
    "    out = []\n",
    "    ix = 0 # set index\n",
    "    while True:\n",
    "        p = N[ix].float() # convert that row in tensor to float\n",
    "        p = p / p.sum() # convert to probabilities\n",
    "        ix = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item() # sample from the multinomial distribution\n",
    "        out.append(int2char[ix])\n",
    "        if ix ==0:\n",
    "            break\n",
    "    print(' '.join(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make more efficient by building probability tensor before\n",
    "P = N.float()\n",
    "P /= P.sum(1, keepdim=True) # normalising by sum of rows\n",
    "# note the /= improves efficiency by not creating a new tensor\n",
    "\n",
    "P[0].sum() # proving sum is still 1\n",
    "\n",
    "# broadcasting to divide each row by the sum of the row\n",
    "# 27, 27\n",
    "# 27, 1 \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "j u n i d e .\n",
      "j a n a s a h .\n",
      "p .\n",
      "c o n y .\n",
      "a .\n",
      "n n .\n",
      "k o h i n .\n",
      "t o l i a n .\n",
      "j u e e .\n",
      "k s a h n a a u r a n i l e v i a s .\n",
      "d e d a i n r w i e t a .\n",
      "s s o n i e l y l a r t e .\n",
      "f a v e u m e r i f o n t u m e .\n",
      "p h y n s l e n a r u a n i .\n",
      "c o r e .\n",
      "y a e n o n .\n",
      "k a .\n",
      "j a b d i n e r i m i k i m a y n i n .\n",
      "a n a a s n .\n",
      "s s o r i o n s u s h .\n",
      "d g o s s m i t a n .\n",
      "i l .\n",
      "l e .\n",
      "p a n n .\n",
      "t h a t .\n",
      "j a n r e l i .\n",
      "i s a .\n",
      "d y n .\n",
      "r i j e l u m e m a h a u n a y a l e v a .\n",
      "c a r a r r .\n",
      "j e n .\n",
      "j a n a r t a .\n",
      "m a l y .\n",
      "a b e l y .\n",
      "a .\n",
      "i .\n",
      "l a v a d o n i .\n",
      "t h e m i e l y a w a t .\n",
      "f .\n",
      "m o d a m .\n",
      "t a v i l i t i k i e s a l o e v e r i n .\n",
      "n .\n",
      "e .\n",
      "k a l b r e n e l a h .\n",
      "a n e n .\n",
      "c h .\n",
      "k .\n",
      "j a n .\n",
      "o d r i d r d e n a n i a l i l p e r g h a .\n",
      "t e z r a l e l i a .\n"
     ]
    }
   ],
   "source": [
    "# more efficient verson of name generation using predefined probabiltiy tensor\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "\n",
    "# generating names based on bigram model using probability distribution\n",
    "for i in range(50):\n",
    "    out = []\n",
    "    ix = 0 # set index\n",
    "    while True:\n",
    "        p = P[ix] # selecting probability row from tensor\n",
    "        ix = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item() # sample from the multinomial distribution\n",
    "        out.append(int2char[ix])\n",
    "        if ix ==0:\n",
    "            break\n",
    "    print(' '.join(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".e: 0.0478 -3.0408\n",
      "em: 0.0377 -3.2793\n",
      "mm: 0.0253 -3.6772\n",
      "ma: 0.3899 -0.9418\n",
      "a.: 0.1960 -1.6299\n",
      ".o: 0.0123 -4.3982\n",
      "ol: 0.0780 -2.5508\n",
      "li: 0.1777 -1.7278\n",
      "iv: 0.0152 -4.1867\n",
      "vi: 0.3541 -1.0383\n",
      "ia: 0.1381 -1.9796\n",
      "a.: 0.1960 -1.6299\n",
      ".a: 0.1377 -1.9829\n",
      "av: 0.0246 -3.7045\n",
      "va: 0.2495 -1.3882\n",
      "a.: 0.1960 -1.6299\n",
      ".i: 0.0184 -3.9927\n",
      "is: 0.0743 -2.5990\n",
      "sa: 0.1482 -1.9094\n",
      "ab: 0.0160 -4.1373\n",
      "be: 0.2476 -1.3958\n",
      "el: 0.1590 -1.8386\n",
      "ll: 0.0964 -2.3397\n",
      "la: 0.1879 -1.6717\n",
      "a.: 0.1960 -1.6299\n",
      ".s: 0.0642 -2.7465\n",
      "so: 0.0655 -2.7256\n",
      "op: 0.0120 -4.4250\n",
      "ph: 0.1988 -1.6153\n",
      "hi: 0.0957 -2.3463\n",
      "ia: 0.1381 -1.9796\n",
      "a.: 0.1960 -1.6299\n",
      ".c: 0.0481 -3.0337\n",
      "ch: 0.1880 -1.6713\n",
      "ha: 0.2946 -1.2220\n",
      "ar: 0.0963 -2.3400\n",
      "rl: 0.0325 -3.4259\n",
      "lo: 0.0496 -3.0042\n",
      "ot: 0.0149 -4.2082\n",
      "tt: 0.0671 -2.7009\n",
      "te: 0.1285 -2.0515\n",
      "e.: 0.1950 -1.6346\n",
      ".m: 0.0792 -2.5354\n",
      "mi: 0.1891 -1.6655\n",
      "ia: 0.1381 -1.9796\n",
      "a.: 0.1960 -1.6299\n",
      ".a: 0.1377 -1.9829\n",
      "am: 0.0482 -3.0319\n",
      "me: 0.1232 -2.0943\n",
      "el: 0.1590 -1.8386\n",
      "li: 0.1777 -1.7278\n",
      "ia: 0.1381 -1.9796\n",
      "a.: 0.1960 -1.6299\n",
      ".h: 0.0273 -3.6014\n",
      "ha: 0.2946 -1.2220\n",
      "ar: 0.0963 -2.3400\n",
      "rp: 0.0011 -6.8103\n",
      "pe: 0.1920 -1.6502\n",
      "er: 0.0959 -2.3447\n",
      "r.: 0.1084 -2.2217\n",
      ".e: 0.0478 -3.0408\n",
      "ev: 0.0227 -3.7867\n",
      "ve: 0.2208 -1.5107\n",
      "el: 0.1590 -1.8386\n",
      "ly: 0.1138 -2.1736\n",
      "yn: 0.1868 -1.6778\n",
      "n.: 0.3690 -0.9969\n",
      "-160.3712\n",
      "2.3936007022857666\n"
     ]
    }
   ],
   "source": [
    "# Evaluating performance of model using log-loss method\n",
    "# this is buggy if it has to evaluate any pair of characters that are not in the training set\n",
    "# as the probability will be 0\n",
    "# To overcome this you add a small value to the probability to avoid log(0) (e.g. P[ix1, ix2] + 1)\n",
    "\n",
    "log_likelihood = 0\n",
    "n = 0\n",
    "\n",
    "for w in words[:10]:\n",
    "    chs = ['.'] + list(w) + ['.']\n",
    "    for ch1, ch2 in zip(chs, chs[1:]):\n",
    "        ix1 = char2int[ch1]\n",
    "        ix2 = char2int[ch2]\n",
    "        prob = P[ix1, ix2]\n",
    "        logprob = torch.log(prob)\n",
    "        log_likelihood += logprob\n",
    "        n+=1\n",
    "        print(f'{ch1}{ch2}: {prob:.4f} {logprob:.4f}')\n",
    "\n",
    "print(f'{log_likelihood:.4f}')\n",
    "nll = -log_likelihood\n",
    "print(f'{nll/n}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write in a better neural network type way\n",
    "\n",
    "# create training set of all bigrams\n",
    "\n",
    "# xs are input to neurons, ys are the target outputs (i.e. next letter)\n",
    "xs, ys = [], []\n",
    "for w in words[:1]:\n",
    "    chs = ['.'] + list(w) + ['.']\n",
    "    for ch1, ch2 in zip(chs, chs[1:]):\n",
    "        ix1 = char2int[ch1]\n",
    "        ix2 = char2int[ch2]\n",
    "        xs.append(ix1)\n",
    "        ys.append(ix2)\n",
    "\n",
    "xs = torch.tensor(xs) # note lower case tensor not Tensor because it keeps the same data type\n",
    "ys = torch.tensor(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2331dc0d510>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "# one hot encoding (google it)\n",
    "#basically ir creates a tensor of zeros with a 1 in the position of the character\n",
    "xenc = F.one_hot(xs, num_classes=27).float() # need float to feed NN\n",
    "plt.imshow(xenc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FORWARD PASS ###\n",
    "\n",
    "# 27 x 27 matrix from normal distribution\n",
    "W = torch.randn((27, 27), requires_grad=True) # requires_grad=True means we can differentiate through this tensor\n",
    "\n",
    "# matrix multiplication using @ \n",
    "# interpret output of multiplication as log counts\n",
    "logits = (xenc @ W)\n",
    "counts = logits.exp() # equivalent to the N matrix of counts from before\n",
    "probs = counts / counts.sum(1, keepdim=True) # normalising by sum of row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can find loss function\n",
    "\n",
    "loss = - probs[torch.arange(5), ys].log().mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BACKWARD PASS ###\n",
    "W.grad = None # zero the gradients\n",
    "loss.backward() # backpropagate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---- Optimisation ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset\n",
    "xs, ys = [], []\n",
    "for w in words[:1000]:\n",
    "    chs = ['.'] + list(w) + ['.']\n",
    "    for ch1, ch2 in zip(chs, chs[1:]):\n",
    "        ix1 = char2int[ch1]\n",
    "        ix2 = char2int[ch2]\n",
    "        xs.append(ix1)\n",
    "        ys.append(ix2)\n",
    "xs = torch.tensor(xs) \n",
    "ys = torch.tensor(ys)\n",
    "num =xs.nelement()\n",
    "\n",
    "# Initialise the 'network' (i.e. the matrix W)\n",
    "# g = torch.Generator().manual_seed(2147483647)\n",
    "W = torch.randn((27, 27), requires_grad=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8549063205718994\n",
      "3.8394389152526855\n",
      "3.8243095874786377\n",
      "3.809495449066162\n",
      "3.7949752807617188\n",
      "3.7807304859161377\n",
      "3.7667458057403564\n",
      "3.7530040740966797\n",
      "3.739492416381836\n",
      "3.726198673248291\n",
      "3.713111162185669\n",
      "3.7002201080322266\n",
      "3.6875171661376953\n",
      "3.6749932765960693\n",
      "3.662641763687134\n",
      "3.6504549980163574\n",
      "3.6384284496307373\n",
      "3.626555919647217\n",
      "3.614832639694214\n",
      "3.6032533645629883\n",
      "3.591815710067749\n",
      "3.580514907836914\n",
      "3.5693488121032715\n",
      "3.558314085006714\n",
      "3.547407388687134\n",
      "3.5366272926330566\n",
      "3.5259716510772705\n",
      "3.5154383182525635\n",
      "3.505025625228882\n",
      "3.4947316646575928\n",
      "3.484556198120117\n",
      "3.4744975566864014\n",
      "3.4645543098449707\n",
      "3.454725742340088\n",
      "3.4450109004974365\n",
      "3.4354097843170166\n",
      "3.4259204864501953\n",
      "3.4165432453155518\n",
      "3.407277822494507\n",
      "3.398123025894165\n",
      "3.389078140258789\n",
      "3.380143642425537\n",
      "3.3713185787200928\n",
      "3.362603187561035\n",
      "3.3539958000183105\n",
      "3.3454973697662354\n",
      "3.337106227874756\n",
      "3.3288228511810303\n",
      "3.320646286010742\n",
      "3.31257700920105\n",
      "3.3046131134033203\n",
      "3.2967545986175537\n",
      "3.289000988006592\n",
      "3.2813525199890137\n",
      "3.27380633354187\n",
      "3.2663633823394775\n",
      "3.2590219974517822\n",
      "3.251781702041626\n",
      "3.2446415424346924\n",
      "3.237600326538086\n",
      "3.2306575775146484\n",
      "3.223811149597168\n",
      "3.2170610427856445\n",
      "3.210405111312866\n",
      "3.203842878341675\n",
      "3.1973721981048584\n",
      "3.1909921169281006\n",
      "3.184701681137085\n",
      "3.1784982681274414\n",
      "3.172382354736328\n",
      "3.166351079940796\n",
      "3.160402774810791\n",
      "3.1545369625091553\n",
      "3.1487514972686768\n",
      "3.14304518699646\n",
      "3.137415885925293\n",
      "3.1318628787994385\n",
      "3.1263833045959473\n",
      "3.1209769248962402\n",
      "3.1156420707702637\n",
      "3.110377311706543\n",
      "3.105180025100708\n",
      "3.100050210952759\n",
      "3.0949857234954834\n",
      "3.0899858474731445\n",
      "3.085048198699951\n",
      "3.080172061920166\n",
      "3.0753555297851562\n",
      "3.0705981254577637\n",
      "3.0658979415893555\n",
      "3.0612542629241943\n",
      "3.0566658973693848\n",
      "3.052131175994873\n",
      "3.047649383544922\n",
      "3.0432190895080566\n",
      "3.038839817047119\n",
      "3.0345101356506348\n",
      "3.030229330062866\n",
      "3.025996446609497\n",
      "3.0218095779418945\n",
      "3.017669200897217\n",
      "3.0135738849639893\n",
      "3.0095226764678955\n",
      "3.005514621734619\n",
      "3.00154972076416\n",
      "2.997626543045044\n",
      "2.993744373321533\n",
      "2.9899027347564697\n",
      "2.986100435256958\n",
      "2.9823381900787354\n",
      "2.978614091873169\n",
      "2.9749276638031006\n",
      "2.971278667449951\n",
      "2.9676666259765625\n",
      "2.9640908241271973\n",
      "2.960550308227539\n",
      "2.9570446014404297\n",
      "2.95357346534729\n",
      "2.95013689994812\n",
      "2.9467339515686035\n",
      "2.943364143371582\n",
      "2.94002628326416\n",
      "2.9367213249206543\n",
      "2.9334475994110107\n",
      "2.930205821990967\n",
      "2.926995038986206\n",
      "2.923814296722412\n",
      "2.920663833618164\n",
      "2.9175431728363037\n",
      "2.914451837539673\n",
      "2.911389112472534\n",
      "2.908355474472046\n",
      "2.9053499698638916\n",
      "2.9023725986480713\n",
      "2.8994221687316895\n",
      "2.8964991569519043\n",
      "2.8936030864715576\n",
      "2.8907337188720703\n",
      "2.887890338897705\n",
      "2.885073184967041\n",
      "2.8822808265686035\n",
      "2.879514694213867\n",
      "2.876772880554199\n",
      "2.874055862426758\n",
      "2.8713631629943848\n",
      "2.86869478225708\n",
      "2.8660497665405273\n",
      "2.8634285926818848\n",
      "2.860830307006836\n",
      "2.8582546710968018\n",
      "2.8557024002075195\n",
      "2.8531715869903564\n",
      "2.850663423538208\n",
      "2.848176956176758\n",
      "2.845712184906006\n",
      "2.843268394470215\n",
      "2.840846061706543\n",
      "2.838444232940674\n",
      "2.8360626697540283\n",
      "2.8337013721466064\n",
      "2.8313608169555664\n",
      "2.8290390968322754\n",
      "2.826737642288208\n",
      "2.8244552612304688\n",
      "2.8221917152404785\n",
      "2.8199472427368164\n",
      "2.817721366882324\n",
      "2.815514087677002\n",
      "2.8133246898651123\n",
      "2.8111531734466553\n",
      "2.8089990615844727\n",
      "2.8068630695343018\n",
      "2.804744005203247\n",
      "2.8026421070098877\n",
      "2.8005571365356445\n",
      "2.7984890937805176\n",
      "2.7964370250701904\n",
      "2.794401168823242\n",
      "2.792381763458252\n",
      "2.7903783321380615\n",
      "2.7883899211883545\n",
      "2.786417245864868\n",
      "2.7844605445861816\n",
      "2.782518148422241\n",
      "2.7805910110473633\n",
      "2.778679132461548\n",
      "2.776780843734741\n",
      "2.774897575378418\n",
      "2.7730283737182617\n",
      "2.7711734771728516\n",
      "2.76933217048645\n",
      "2.7675044536590576\n",
      "2.765690803527832\n",
      "2.763890266418457\n",
      "2.7621030807495117\n",
      "2.760329008102417\n",
      "2.758568048477173\n",
      "2.756819725036621\n",
      "2.7550837993621826\n",
      "2.7533605098724365\n",
      "2.751650094985962\n",
      "2.7499513626098633\n",
      "2.748264789581299\n",
      "2.7465903759002686\n",
      "2.744927167892456\n",
      "2.7432758808135986\n",
      "2.7416365146636963\n",
      "2.7400083541870117\n",
      "2.738391399383545\n",
      "2.736785650253296\n",
      "2.7351906299591064\n",
      "2.7336068153381348\n",
      "2.7320339679718018\n",
      "2.73047137260437\n",
      "2.728919506072998\n",
      "2.7273783683776855\n",
      "2.725847005844116\n",
      "2.7243258953094482\n",
      "2.72281551361084\n",
      "2.7213144302368164\n",
      "2.7198235988616943\n",
      "2.7183423042297363\n",
      "2.7168710231781006\n",
      "2.715409278869629\n",
      "2.713956594467163\n",
      "2.7125136852264404\n",
      "2.7110798358917236\n",
      "2.7096550464630127\n",
      "2.7082393169403076\n",
      "2.7068333625793457\n",
      "2.7054355144500732\n",
      "2.7040467262268066\n",
      "2.7026662826538086\n",
      "2.7012948989868164\n",
      "2.699932336807251\n",
      "2.6985771656036377\n",
      "2.6972315311431885\n",
      "2.6958937644958496\n",
      "2.694563865661621\n",
      "2.6932425498962402\n",
      "2.6919291019439697\n",
      "2.6906232833862305\n",
      "2.6893258094787598\n",
      "2.6880359649658203\n",
      "2.686753988265991\n",
      "2.6854801177978516\n",
      "2.684213161468506\n",
      "2.6829538345336914\n",
      "2.681702136993408\n",
      "2.680457592010498\n",
      "2.679220676422119\n",
      "2.6779909133911133\n",
      "2.6767683029174805\n",
      "2.6755526065826416\n",
      "2.674344301223755\n",
      "2.673142671585083\n",
      "2.671948194503784\n",
      "2.6707606315612793\n",
      "2.6695797443389893\n",
      "2.668405771255493\n",
      "2.6672379970550537\n",
      "2.6660773754119873\n",
      "2.6649231910705566\n",
      "2.6637754440307617\n",
      "2.6626341342926025\n",
      "2.661499261856079\n",
      "2.6603705883026123\n",
      "2.6592483520507812\n",
      "2.658132314682007\n",
      "2.657022714614868\n",
      "2.6559183597564697\n",
      "2.6548211574554443\n",
      "2.6537294387817383\n",
      "2.6526436805725098\n",
      "2.651563882827759\n",
      "2.6504900455474854\n",
      "2.6494219303131104\n",
      "2.648359775543213\n",
      "2.647303581237793\n",
      "2.646252393722534\n",
      "2.645206928253174\n",
      "2.644167423248291\n",
      "2.6431331634521484\n",
      "2.6421051025390625\n",
      "2.6410818099975586\n",
      "2.640064001083374\n",
      "2.639051675796509\n",
      "2.638045072555542\n",
      "2.637042999267578\n",
      "2.6360464096069336\n",
      "2.6350553035736084\n",
      "2.6340694427490234\n",
      "2.6330885887145996\n",
      "2.632112741470337\n",
      "2.6311416625976562\n",
      "2.630175828933716\n",
      "2.6292150020599365\n",
      "2.6282591819763184\n",
      "2.627307891845703\n",
      "2.6263620853424072\n",
      "2.625420331954956\n",
      "2.624484062194824\n",
      "2.6235523223876953\n",
      "2.6226253509521484\n",
      "2.6217024326324463\n",
      "2.6207847595214844\n",
      "2.6198718547821045\n",
      "2.6189634799957275\n",
      "2.6180593967437744\n",
      "2.617159843444824\n",
      "2.6162643432617188\n",
      "2.6153738498687744\n",
      "2.614487648010254\n",
      "2.6136059761047363\n",
      "2.6127285957336426\n",
      "2.6118552684783936\n",
      "2.6109864711761475\n",
      "2.610121726989746\n",
      "2.6092615127563477\n",
      "2.608405590057373\n",
      "2.607553720474243\n",
      "2.6067054271698\n",
      "2.6058616638183594\n",
      "2.6050217151641846\n",
      "2.6041860580444336\n",
      "2.6033549308776855\n",
      "2.602527141571045\n",
      "2.601703405380249\n",
      "2.6008832454681396\n",
      "2.600067615509033\n",
      "2.5992558002471924\n",
      "2.598447799682617\n",
      "2.5976436138153076\n",
      "2.5968430042266846\n",
      "2.596046209335327\n",
      "2.5952534675598145\n",
      "2.5944643020629883\n",
      "2.5936784744262695\n",
      "2.5928966999053955\n",
      "2.592118978500366\n",
      "2.591344118118286\n",
      "2.59057354927063\n",
      "2.5898056030273438\n",
      "2.5890419483184814\n",
      "2.5882816314697266\n",
      "2.587524890899658\n",
      "2.5867719650268555\n",
      "2.586021900177002\n",
      "2.585275888442993\n",
      "2.5845322608947754\n",
      "2.5837929248809814\n",
      "2.583056926727295\n",
      "2.5823240280151367\n",
      "2.581594705581665\n",
      "2.5808680057525635\n",
      "2.5801453590393066\n",
      "2.57942533493042\n",
      "2.578709125518799\n",
      "2.577995777130127\n",
      "2.5772857666015625\n",
      "2.5765790939331055\n",
      "2.5758755207061768\n",
      "2.5751748085021973\n",
      "2.574477434158325\n",
      "2.5737829208374023\n",
      "2.573091745376587\n",
      "2.572403907775879\n",
      "2.571718692779541\n",
      "2.5710361003875732\n",
      "2.570357084274292\n",
      "2.569681167602539\n",
      "2.5690078735351562\n",
      "2.5683376789093018\n",
      "2.5676703453063965\n",
      "2.5670061111450195\n",
      "2.566344738006592\n",
      "2.565685510635376\n",
      "2.5650298595428467\n",
      "2.5643768310546875\n",
      "2.5637271404266357\n",
      "2.563079595565796\n",
      "2.5624351501464844\n",
      "2.561793327331543\n",
      "2.561154365539551\n",
      "2.5605180263519287\n",
      "2.5598843097686768\n",
      "2.559253454208374\n",
      "2.5586252212524414\n",
      "2.557999610900879\n",
      "2.5573768615722656\n",
      "2.5567564964294434\n",
      "2.556138753890991\n",
      "2.5555241107940674\n",
      "2.5549116134643555\n",
      "2.5543015003204346\n",
      "2.553694248199463\n",
      "2.5530893802642822\n",
      "2.5524868965148926\n",
      "2.5518875122070312\n",
      "2.5512900352478027\n",
      "2.5506951808929443\n",
      "2.550102710723877\n",
      "2.549513339996338\n",
      "2.5489253997802734\n",
      "2.548340320587158\n",
      "2.547757625579834\n",
      "2.54717755317688\n",
      "2.5465996265411377\n",
      "2.5460240840911865\n",
      "2.5454506874084473\n",
      "2.5448801517486572\n",
      "2.544311761856079\n",
      "2.543745279312134\n",
      "2.5431814193725586\n",
      "2.5426197052001953\n",
      "2.542060375213623\n",
      "2.5415031909942627\n",
      "2.5409481525421143\n",
      "2.540395736694336\n",
      "2.5398454666137695\n",
      "2.539297103881836\n",
      "2.5387508869171143\n",
      "2.5382068157196045\n",
      "2.5376651287078857\n",
      "2.537125825881958\n",
      "2.536588430404663\n",
      "2.53605318069458\n",
      "2.53551983833313\n",
      "2.5349888801574707\n",
      "2.534459352493286\n",
      "2.533932685852051\n",
      "2.5334079265594482\n",
      "2.5328850746154785\n",
      "2.5323646068573\n",
      "2.5318455696105957\n",
      "2.5313286781311035\n",
      "2.5308139324188232\n",
      "2.530301332473755\n",
      "2.5297908782958984\n",
      "2.5292818546295166\n",
      "2.528775453567505\n",
      "2.5282704830169678\n",
      "2.5277676582336426\n",
      "2.527266263961792\n",
      "2.5267672538757324\n",
      "2.5262696743011475\n",
      "2.5257749557495117\n",
      "2.5252814292907715\n",
      "2.524789571762085\n",
      "2.5243000984191895\n",
      "2.5238120555877686\n",
      "2.5233263969421387\n",
      "2.5228424072265625\n",
      "2.52236008644104\n",
      "2.521878957748413\n",
      "2.5214004516601562\n",
      "2.5209238529205322\n",
      "2.520448923110962\n",
      "2.5199756622314453\n",
      "2.5195040702819824\n",
      "2.519033908843994\n",
      "2.5185656547546387\n",
      "2.518099784851074\n",
      "2.517634630203247\n",
      "2.51717209815979\n",
      "2.5167105197906494\n",
      "2.5162510871887207\n",
      "2.5157933235168457\n",
      "2.5153369903564453\n",
      "2.514882802963257\n",
      "2.514430046081543\n",
      "2.5139784812927246\n",
      "2.5135293006896973\n",
      "2.5130810737609863\n",
      "2.512634754180908\n",
      "2.512190341949463\n",
      "2.511747121810913\n",
      "2.511305809020996\n",
      "2.5108659267425537\n",
      "2.510427474975586\n",
      "2.509990930557251\n",
      "2.5095558166503906\n",
      "2.509121894836426\n",
      "2.508690357208252\n",
      "2.5082592964172363\n",
      "2.507830858230591\n",
      "2.5074031352996826\n",
      "2.506977081298828\n",
      "2.5065529346466064\n",
      "2.506129741668701\n",
      "2.5057082176208496\n",
      "2.5052883625030518\n",
      "2.5048701763153076\n",
      "2.504452705383301\n",
      "2.5040371417999268\n",
      "2.5036230087280273\n",
      "2.5032105445861816\n",
      "2.5027995109558105\n",
      "2.502389430999756\n",
      "2.501981258392334\n",
      "2.5015738010406494\n",
      "2.5011684894561768\n",
      "2.5007641315460205\n",
      "2.500361680984497\n",
      "2.499959945678711\n",
      "2.4995601177215576\n",
      "2.4991614818573\n",
      "2.4987640380859375\n",
      "2.498368501663208\n",
      "2.497973918914795\n",
      "2.4975807666778564\n",
      "2.4971885681152344\n",
      "2.496798038482666\n",
      "2.496408700942993\n",
      "2.496020793914795\n",
      "2.4956343173980713\n",
      "2.4952492713928223\n",
      "2.4948649406433105\n",
      "2.4944820404052734\n",
      "2.494100570678711\n",
      "2.493720531463623\n",
      "2.4933414459228516\n",
      "2.492964267730713\n",
      "2.4925875663757324\n",
      "2.4922127723693848\n",
      "2.4918384552001953\n",
      "2.4914658069610596\n",
      "2.4910943508148193\n",
      "2.4907240867614746\n",
      "2.4903552532196045\n",
      "2.48998761177063\n",
      "2.489621162414551\n",
      "2.489255666732788\n",
      "2.488891124725342\n",
      "2.488528251647949\n",
      "2.488166332244873\n",
      "2.4878063201904297\n",
      "2.4874463081359863\n",
      "2.487088441848755\n",
      "2.4867308139801025\n",
      "2.486375331878662\n",
      "2.48602032661438\n",
      "2.485666513442993\n",
      "2.485314130783081\n",
      "2.4849627017974854\n",
      "2.484612464904785\n",
      "2.4842629432678223\n",
      "2.483915090560913\n",
      "2.483567953109741\n",
      "2.483222007751465\n",
      "2.482877254486084\n",
      "2.4825339317321777\n",
      "2.4821910858154297\n",
      "2.4818499088287354\n",
      "2.4815094470977783\n",
      "2.4811697006225586\n",
      "2.4808318614959717\n",
      "2.480494499206543\n",
      "2.480158567428589\n",
      "2.479823350906372\n",
      "2.4794888496398926\n",
      "2.479156255722046\n",
      "2.4788241386413574\n",
      "2.4784932136535645\n",
      "2.478163242340088\n",
      "2.4778342247009277\n",
      "2.477506637573242\n",
      "2.4771792888641357\n",
      "2.476853609085083\n",
      "2.476529121398926\n",
      "2.4762051105499268\n",
      "2.475882053375244\n",
      "2.475560188293457\n",
      "2.4752392768859863\n",
      "2.474919319152832\n",
      "2.474600315093994\n",
      "2.4742822647094727\n",
      "2.4739654064178467\n",
      "2.473649263381958\n",
      "2.4733338356018066\n",
      "2.47301983833313\n",
      "2.4727067947387695\n",
      "2.4723942279815674\n",
      "2.472083330154419\n",
      "2.4717724323272705\n",
      "2.471463203430176\n",
      "2.4711546897888184\n",
      "2.4708468914031982\n",
      "2.4705402851104736\n",
      "2.4702346324920654\n",
      "2.4699294567108154\n",
      "2.469625473022461\n",
      "2.4693219661712646\n",
      "2.469020128250122\n",
      "2.4687187671661377\n",
      "2.4684183597564697\n",
      "2.468118906021118\n",
      "2.467820167541504\n",
      "2.467522382736206\n",
      "2.4672255516052246\n",
      "2.4669294357299805\n",
      "2.466634511947632\n",
      "2.4663403034210205\n",
      "2.4660468101501465\n",
      "2.4657537937164307\n",
      "2.4654619693756104\n",
      "2.4651715755462646\n",
      "2.464881181716919\n",
      "2.4645919799804688\n",
      "2.4643032550811768\n",
      "2.4640157222747803\n",
      "2.4637291431427\n",
      "2.4634432792663574\n",
      "2.463157892227173\n",
      "2.462873697280884\n",
      "2.462590217590332\n",
      "2.4623072147369385\n",
      "2.4620258808135986\n",
      "2.4617443084716797\n",
      "2.4614639282226562\n",
      "2.461184501647949\n",
      "2.4609057903289795\n",
      "2.460628032684326\n",
      "2.460350513458252\n",
      "2.460073947906494\n",
      "2.459798812866211\n",
      "2.459523916244507\n",
      "2.45924973487854\n",
      "2.4589767456054688\n",
      "2.4587039947509766\n",
      "2.4584319591522217\n",
      "2.458160877227783\n",
      "2.457890748977661\n",
      "2.457620859146118\n",
      "2.45735239982605\n",
      "2.4570841789245605\n",
      "2.4568169116973877\n",
      "2.456550359725952\n",
      "2.456284523010254\n",
      "2.456019639968872\n",
      "2.4557549953460693\n",
      "2.455491542816162\n",
      "2.455228567123413\n",
      "2.4549663066864014\n",
      "2.454704761505127\n",
      "2.45444393157959\n",
      "2.45418381690979\n",
      "2.4539241790771484\n",
      "2.4536659717559814\n",
      "2.4534077644348145\n",
      "2.453150510787964\n",
      "2.4528937339782715\n",
      "2.4526374340057373\n",
      "2.4523825645446777\n",
      "2.4521279335021973\n",
      "2.451874256134033\n",
      "2.4516208171844482\n",
      "2.4513683319091797\n",
      "2.4511165618896484\n",
      "2.4508650302886963\n",
      "2.4506146907806396\n",
      "2.450364828109741\n",
      "2.450115919113159\n",
      "2.4498672485351562\n",
      "2.4496192932128906\n",
      "2.4493720531463623\n",
      "2.4491255283355713\n",
      "2.4488794803619385\n",
      "2.448634147644043\n",
      "2.4483895301818848\n",
      "2.448145627975464\n",
      "2.447902202606201\n",
      "2.4476592540740967\n",
      "2.4474172592163086\n",
      "2.4471757411956787\n",
      "2.446934700012207\n",
      "2.4466943740844727\n",
      "2.446455240249634\n",
      "2.446215867996216\n",
      "2.4459774494171143\n",
      "2.44573974609375\n",
      "2.445502519607544\n",
      "2.4452662467956543\n",
      "2.4450299739837646\n",
      "2.4447948932647705\n",
      "2.4445602893829346\n",
      "2.4443259239196777\n",
      "2.4440925121307373\n",
      "2.443859338760376\n",
      "2.443627119064331\n",
      "2.4433953762054443\n",
      "2.443164348602295\n",
      "2.4429335594177246\n",
      "2.4427034854888916\n",
      "2.442474365234375\n",
      "2.4422447681427\n",
      "2.442017078399658\n",
      "2.441789150238037\n",
      "2.4415619373321533\n",
      "2.441335439682007\n",
      "2.4411094188690186\n",
      "2.4408836364746094\n",
      "2.4406590461730957\n",
      "2.440434455871582\n",
      "2.4402105808258057\n",
      "2.4399876594543457\n",
      "2.439765214920044\n",
      "2.439542531967163\n",
      "2.439321279525757\n",
      "2.439100503921509\n",
      "2.4388794898986816\n",
      "2.438659906387329\n",
      "2.4384403228759766\n",
      "2.4382214546203613\n",
      "2.4380033016204834\n",
      "2.4377849102020264\n",
      "2.437567949295044\n",
      "2.4373512268066406\n",
      "2.4371352195739746\n",
      "2.4369194507598877\n",
      "2.436704158782959\n",
      "2.4364895820617676\n",
      "2.4362754821777344\n",
      "2.436061382293701\n",
      "2.4358484745025635\n",
      "2.435636043548584\n",
      "2.435424327850342\n",
      "2.4352126121520996\n",
      "2.4350011348724365\n",
      "2.434790849685669\n",
      "2.4345805644989014\n",
      "2.4343714714050293\n",
      "2.434162139892578\n",
      "2.4339537620544434\n",
      "2.4337456226348877\n",
      "2.4335379600524902\n",
      "2.43333101272583\n",
      "2.433124303817749\n",
      "2.4329185485839844\n",
      "2.4327125549316406\n",
      "2.4325077533721924\n",
      "2.432302951812744\n",
      "2.432098865509033\n",
      "2.4318950176239014\n",
      "2.431692123413086\n",
      "2.4314892292022705\n",
      "2.4312868118286133\n",
      "2.4310851097106934\n",
      "2.4308836460113525\n",
      "2.43068265914917\n",
      "2.4304826259613037\n",
      "2.4302825927734375\n",
      "2.4300832748413086\n",
      "2.4298839569091797\n",
      "2.429685592651367\n",
      "2.429487705230713\n",
      "2.4292898178100586\n",
      "2.4290928840637207\n",
      "2.428896188735962\n",
      "2.4286997318267822\n",
      "2.4285037517547607\n",
      "2.4283084869384766\n",
      "2.4281139373779297\n",
      "2.4279191493988037\n",
      "2.427725076675415\n",
      "2.4275319576263428\n",
      "2.4273386001586914\n",
      "2.4271459579467773\n",
      "2.4269535541534424\n",
      "2.426762104034424\n",
      "2.4265706539154053\n",
      "2.426379442214966\n",
      "2.4261887073516846\n",
      "2.425999164581299\n",
      "2.425809144973755\n",
      "2.4256198406219482\n",
      "2.4254310131073\n",
      "2.4252429008483887\n",
      "2.4250547885894775\n",
      "2.4248669147491455\n",
      "2.42467999458313\n",
      "2.4244933128356934\n",
      "2.424307107925415\n",
      "2.424121379852295\n",
      "2.423935890197754\n",
      "2.423750638961792\n",
      "2.4235658645629883\n",
      "2.4233815670013428\n",
      "2.4231977462768555\n",
      "2.4230144023895264\n",
      "2.4228317737579346\n",
      "2.4226486682891846\n",
      "2.42246675491333\n",
      "2.4222848415374756\n",
      "2.4221034049987793\n",
      "2.421922206878662\n",
      "2.4217417240142822\n",
      "2.4215612411499023\n",
      "2.4213814735412598\n",
      "2.4212019443511963\n",
      "2.421022891998291\n",
      "2.420844554901123\n",
      "2.420666217803955\n",
      "2.4204883575439453\n",
      "2.4203104972839355\n",
      "2.420133590698242\n",
      "2.419956922531128\n",
      "2.4197804927825928\n",
      "2.419604539871216\n",
      "2.419428825378418\n",
      "2.4192535877227783\n",
      "2.4190785884857178\n",
      "2.4189047813415527\n",
      "2.4187304973602295\n",
      "2.4185564517974854\n",
      "2.4183833599090576\n",
      "2.41821026802063\n",
      "2.4180376529693604\n",
      "2.41786527633667\n",
      "2.417693853378296\n",
      "2.4175217151641846\n",
      "2.4173502922058105\n",
      "2.417179822921753\n",
      "2.4170093536376953\n",
      "2.416839361190796\n",
      "2.4166698455810547\n",
      "2.4165003299713135\n",
      "2.4163312911987305\n",
      "2.4161627292633057\n",
      "2.415994167327881\n",
      "2.4158265590667725\n",
      "2.415658473968506\n",
      "2.4154913425445557\n",
      "2.4153244495391846\n",
      "2.415158271789551\n",
      "2.414992332458496\n",
      "2.414825916290283\n",
      "2.414660692214966\n",
      "2.4144949913024902\n",
      "2.4143307209014893\n",
      "2.41416597366333\n",
      "2.4140021800994873\n",
      "2.4138381481170654\n",
      "2.4136743545532227\n",
      "2.4135115146636963\n",
      "2.413348913192749\n",
      "2.4131863117218018\n",
      "2.4130239486694336\n",
      "2.412862539291382\n",
      "2.412700891494751\n",
      "2.4125399589538574\n",
      "2.412379264831543\n",
      "2.4122185707092285\n",
      "2.412058115005493\n",
      "2.411898374557495\n",
      "2.4117393493652344\n",
      "2.4115798473358154\n",
      "2.411421060562134\n",
      "2.4112627506256104\n",
      "2.411104679107666\n",
      "2.4109463691711426\n",
      "2.4107890129089355\n",
      "2.4106318950653076\n",
      "2.410475015640259\n",
      "2.410318374633789\n",
      "2.4101622104644775\n",
      "2.410006284713745\n",
      "2.409850597381592\n",
      "2.4096951484680176\n",
      "2.4095399379730225\n",
      "2.4093854427337646\n",
      "2.409231185913086\n",
      "2.409076452255249\n",
      "2.4089231491088867\n",
      "2.4087696075439453\n",
      "2.408616542816162\n",
      "2.408463478088379\n",
      "2.408310651779175\n",
      "2.408158540725708\n",
      "2.4080066680908203\n",
      "2.4078547954559326\n",
      "2.4077038764953613\n",
      "2.407552480697632\n",
      "2.4074015617370605\n",
      "2.4072513580322266\n",
      "2.4071011543273926\n",
      "2.4069511890411377\n",
      "2.406801462173462\n",
      "2.4066524505615234\n",
      "2.406503200531006\n",
      "2.4063544273376465\n",
      "2.4062061309814453\n",
      "2.4060583114624023\n",
      "2.405910015106201\n",
      "2.4057626724243164\n",
      "2.4056150913238525\n",
      "2.405468463897705\n",
      "2.4053215980529785\n",
      "2.4051754474639893\n",
      "2.405029058456421\n",
      "2.40488338470459\n",
      "2.404737710952759\n",
      "2.404592752456665\n",
      "2.404447555541992\n",
      "2.4043028354644775\n",
      "2.404158592224121\n",
      "2.4040141105651855\n",
      "2.4038703441619873\n",
      "2.40372633934021\n",
      "2.403583288192749\n",
      "2.403440237045288\n",
      "2.4032979011535645\n",
      "2.4031546115875244\n",
      "2.403012752532959\n",
      "2.4028706550598145\n",
      "2.402729034423828\n",
      "2.402587890625\n",
      "2.4024462699890137\n",
      "2.4023056030273438\n",
      "2.402164936065674\n",
      "2.402024507522583\n",
      "2.4018845558166504\n",
      "2.4017446041107178\n",
      "2.4016051292419434\n",
      "2.401465654373169\n",
      "2.401326894760132\n",
      "2.4011878967285156\n",
      "2.4010496139526367\n",
      "2.400911331176758\n",
      "2.400773286819458\n",
      "2.4006354808807373\n",
      "2.400498151779175\n",
      "2.4003610610961914\n",
      "2.400223970413208\n",
      "2.4000871181488037\n",
      "2.399951219558716\n",
      "2.3998143672943115\n",
      "2.3996782302856445\n",
      "2.399543046951294\n",
      "2.399407386779785\n",
      "2.3992722034454346\n",
      "2.399137496948242\n",
      "2.39900279045105\n",
      "2.3988680839538574\n",
      "2.3987338542938232\n",
      "2.398599863052368\n",
      "2.398466110229492\n",
      "2.3983330726623535\n",
      "2.398200035095215\n",
      "2.398066997528076\n",
      "2.3979341983795166\n",
      "2.397801637649536\n",
      "2.3976693153381348\n",
      "2.3975374698638916\n",
      "2.3974061012268066\n",
      "2.3972744941711426\n",
      "2.3971431255340576\n",
      "2.397012233734131\n",
      "2.396881580352783\n",
      "2.3967506885528564\n",
      "2.396620512008667\n",
      "2.3964905738830566\n",
      "2.396360397338867\n",
      "2.396230697631836\n",
      "2.396101951599121\n",
      "2.395972728729248\n",
      "2.395843744277954\n",
      "2.3957152366638184\n",
      "2.3955867290496826\n",
      "2.395458221435547\n",
      "2.3953301906585693\n",
      "2.39520263671875\n",
      "2.3950753211975098\n",
      "2.3949482440948486\n",
      "2.3948209285736084\n",
      "2.3946943283081055\n",
      "2.3945674896240234\n",
      "2.3944411277770996\n",
      "2.394315242767334\n",
      "2.3941893577575684\n",
      "2.3940634727478027\n",
      "2.3939380645751953\n",
      "2.393813133239746\n",
      "2.3936879634857178\n",
      "2.3935630321502686\n",
      "2.3934383392333984\n",
      "2.3933138847351074\n",
      "2.3931899070739746\n",
      "2.393065929412842\n",
      "2.392942428588867\n",
      "2.3928191661834717\n",
      "2.3926961421966553\n",
      "2.3925728797912598\n",
      "2.3924500942230225\n",
      "2.392327308654785\n",
      "2.392204999923706\n",
      "2.392082691192627\n",
      "2.391961097717285\n",
      "2.3918395042419434\n",
      "2.3917176723480225\n"
     ]
    }
   ],
   "source": [
    "# gradienst descent\n",
    "for k in range(1000):\n",
    "\n",
    "    #forward pass\n",
    "    xenc = F.one_hot(xs, num_classes=27).float()\n",
    "    logits = (xenc @ W)\n",
    "    counts = logits.exp()\n",
    "    probs = counts / counts.sum(1, keepdim=True)\n",
    "    loss = - probs[torch.arange(num), ys].log().mean() + 0.01*(W**2).mean() \n",
    "    # 0.01(W**2).mean() is a regularisation term to prevent overfitting\n",
    "\n",
    "    #backward pass\n",
    "    W.grad = None\n",
    "    loss.backward()\n",
    "\n",
    "    #update weights\n",
    "    W.data += -1 * W.grad\n",
    "\n",
    "    print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "j u w j d e .\n",
      "j a n a q a h .\n",
      "p x c f k y .\n",
      "a .\n",
      "b e .\n",
      "k a i .\n",
      "r l t o l i a .\n",
      "s a t e e .\n",
      "k a l a n a d u y a n i l e v i a c e d b d a i n r w i e .\n",
      "l e s e j y .\n"
     ]
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "\n",
    "# generating names based on bigram model using probability distribution\n",
    "for i in range(10):\n",
    "    out = []\n",
    "    ix = 0 # set index\n",
    "\n",
    "    while True:\n",
    "        # p = P[ix] # selecting probability row from tensor\n",
    "        \n",
    "        xenc = F.one_hot(torch.tensor([ix]), num_classes=27).float()\n",
    "        logits = (xenc @ W)\n",
    "        counts = logits.exp()\n",
    "        p = counts / counts.sum(1, keepdims=True)\n",
    "        \n",
    "        \n",
    "        ix = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item() # sample from the multinomial distribution\n",
    "        out.append(int2char[ix])\n",
    "\n",
    "        if ix ==0:\n",
    "            break\n",
    "    print(' '.join(out))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
